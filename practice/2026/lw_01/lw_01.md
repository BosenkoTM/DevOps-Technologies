# Лабораторная работа №1. Работа с Git и GitHub/GitVerse: инициализация, ветвление, управление версиями в аналитическом проекте

## Цель работы
Научиться применять систему контроля версий Git для управления жизненным циклом аналитического проекта: от настройки окружения и инициализации репозитория до работы с ветками (branching), слияния (merging) и разрешения конфликтов при совместной разработке скриптов обработки данных.

## Исходные данные и инструменты
В рамках курса выполняется **сквозной проект**: разработка «Корпоративной платформы аналитики данных» (Corporate Data Analytics Platform — CDAP).
Каждая лабораторная работа развивает этот проект. В ЛР №1 мы закладываем фундамент: структуру проекта, документацию и версионность.

### Используемые источники данных (Real-World Data)
Для выполнения заданий необходимо выбрать набор данных, соответствующий вашему варианту. Данные должны быть реально существующими (доступными для скачивания или обращения по API).

| Категория данных | Описание источника | Примеры реальных наборов (Datasets) |
|:--- |:--- |:--- |
| **Финансы (Finance)** | Котировки акций, криптовалют, финансовая отчетность. Источники: *Yahoo Finance, Kaggle Finance, MOEX API*. | `S&P 500 Stock Data`, `Bitcoin Historical Data`, `Bank Churn Modeling`. |
| **Ритейл (Retail)** | Транзакции, поведение клиентов, продажи. Источники: *UCI Machine Learning Repository, Kaggle Retail*. | `Online Retail II UCI`, `Brazilian E-Commerce Public Dataset`, `Walmart Store Sales`. |
| **Здравоохранение (Healthcare)** | Статистика заболеваний, медицинские показатели. Источники: *WHO (ВОЗ), CDC, Kaggle Health*. | `Heart Disease UCI`, `COVID-19 World Vaccination Progress`, `Diabetes Dataset`. |
| **Логистика и Энергетика (Logistics & Energy)** | Потребление энергии, цепочки поставок, транспорт. Источники: *World Bank Open Data, US Energy Info Admin*. | `Global Energy Consumption`, `Uber Pickups in NYC`, `Traffic Prediction Dataset`. |

## Требования к окружению (Technical Stack)
На основе Практической работы 2-1 (Основы Linux):
-  **ОС:** Ubuntu 22.04/24.04 (в VirtualBox или WSL2 для Windows).
-  **Инструменты:** Git (v 2.30+), SSH-клиент, текстовый редактор (Nano/Vim или VS Code).
-  **Хостинг репозиториев:** GitHub или GitVerse (отечественный аналог).

## Ход работы

### Этап 1. Подготовка окружения (Linux & SSH)
*Базируется на Практической работе 2-1.*
-  Создать пользователя в системе (формат: `student_var<№варианта>`) и наделить его правами `sudo`.
-  Установить `git` и `python3-pip`.
-  Сгенерировать SSH-ключ (`ed25519` или `rsa`) и добавить публичный ключ в настройки профиля GitHub/GitVerse.
-  Настроить глобальную конфигурацию Git (`user.name`, `user.email`).

### Этап 2. Инициализация аналитического проекта
*Базируется на Практической работе 2.2.*
-  Создать локальную директорию проекта в соответствии с принятой в Data Science структурой (например, Cookiecutter Data Science):
    *   `/data` — для сырых данных.
    *   `/notebooks` — для Jupyter ноутбуков.
    *   `/src` — для исходного кода (ETL-скрипты).
-  Инициализировать Git-репозиторий.
-  Создать файл `.gitignore`, исключив системные файлы (`.DS_Store`), временные файлы Python (`__pycache__`, `*.pyc`), виртуальные окружения (`.venv`, `env/`) и **сами файлы данных** (`*.csv`, `*.xlsx`, `*.json`), так как большие данные не хранятся в Git.

### Этап 3. Симуляция командной работы (Ветвление и Конфликты)
-  **Ветка `dev`**: Создать ветку разработки от `main`.
-  **Ветка `feature/data-loader`**: Создать ветку для написания скрипта загрузки данных.
    *   Создать файл `src/loader.py`.
    *   Добавить код (заглушку), имитирующий загрузку данных из вашего источника (см. таблицу данных).
    *   Сделать коммит.
-  **Имитация конфликта**:
    *   Переключиться в `dev`.
    *   Внести изменения в ту же строку файла `src/loader.py` (например, изменить URL источника данных). Сделать коммит.
    *   Сделать слияние (merge) ветки `feature/data-loader` в `dev`.
    *   **Разрешить возникший конфликт** (выбрать один из вариантов или объединить их).
-  **Pull Request (Merge Request)**:
    *   Отправить (push) ветки в удаленный репозиторий.
    *   Оформить слияние `dev` в `main` через интерфейс GitHub/GitVerse.

---

## Варианты заданий (Кейсы)

В таблице ниже представлены задания. Номер варианта соответствует вашему номеру в списке группы.

**Бизнес-задача** описывает проблему, которую решает аналитика. 

**Проектная задача** — конкретный шаг в разработке. 

**Техническое задание** — специфика использования Git для данного варианта.

Задания на образовательном портале [IT-Adaptive](https://envlab.ru/mod/assign/view.php?id=13)

## Формат предоставления результатов

В качестве отчета принимается **только** ссылка на публичный репозиторий (GitHub или GitVerse).
Репозиторий должен содержать:
-  Файл `README.md` с описанием проекта, вашей ФИО, группы и номера варианта.
-  Историю коммитов, отражающую выполнение задания (должно быть видно ветвление, слияние, разрешение конфликтов).
-  Файлы скриптов и документации, соответствующие вашему варианту (содержательная часть файлов может быть минимальной/заглушками, но структура должна быть соблюдена).
-  Скриншоты выполнения ключевых команд (вставленные в `README.md` или папку `docs/`), подтверждающие разрешение конфликтов и работу в консоли, если это требовалось заданием.

**Критерии оценки**

| Критерий | Баллы | Требования к выполнению |
|:---|:---:|:---|
| **1. Инициализация и оформление репозитория** | **1** | Репозиторий создан на GitHub/GitVerse. Наличие файла `README.md` с указанием ФИО, группы, номера варианта и описанием бизнес-задачи. |
| **2. Структура проекта и `.gitignore`** | **2** | Соблюдена структура Data Science проекта (`/data`, `/src`, `/notebooks`). Файл `.gitignore` настроен корректно: в репозитории **отсутствуют** файлы данных (`.csv`, `.xlsx`), системные файлы и виртуальное окружение. |
| **3. Работа с ветками (Branching Strategy)** | **2** | В истории коммитов прослеживается иерархия веток: `main` → `dev` → `feature/...`. Присутствуют операции слияния (Merge/Pull Request). Работа велась не только в `main`. |
| **4. Разрешение конфликтов** | **2** | В истории коммитов явно виден момент параллельного изменения одного файла и последующее разрешение конфликта (Merge Commit или результат слияния). |
| **5. Выполнение варианта (Project & Tech Scope)** | **2** | Реализована проектная задача (созданы соответствующие скрипты/файлы) и выполнено специфическое техническое задание варианта (например, использование тегов, `rebase`, `cherry-pick` и т.д.). |
| **6. Качество истории изменений** | **1** | Коммиты имеют осмысленные названия (Semantic Commits), отражающие суть изменений (например, `"feat: add data loader"`, а не `"update 1"`). |

**Шкала перевода:**
*   **0-4 балла.** Работа не зачтена (не выполнены базовые требования по Git).

*   **5-10 баллов.** Работа зачтена (при условии защиты).
